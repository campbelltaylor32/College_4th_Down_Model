{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourth Down Decision Analysis - Machine Learning Pipeline\n",
    "\n",
    "This notebook trains and evaluates multiple ML classifiers to predict 4th down go-for-it decisions, then calculates **Coach Aggression Over Expectation (AOE)**.\n",
    "\n",
    "## Pipeline Overview\n",
    "1. Load and preprocess data from R pipeline\n",
    "2. Train and evaluate multiple classifiers\n",
    "3. Select best model based on F1-score\n",
    "4. Hyperparameter tuning\n",
    "5. Calculate Aggression Over Expectation for each coach\n",
    "6. Export rankings and predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (accuracy_score, f1_score, classification_report, \n",
    "                             confusion_matrix, roc_auc_score, precision_score, recall_score)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "                              AdaBoostClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import joblib\n",
    "\n",
    "print(\"Core libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ XGBoost available\n",
      "✓ LightGBM available\n"
     ]
    }
   ],
   "source": [
    "# Try to import advanced ML libraries\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGBOOST_AVAILABLE = True\n",
    "    print(\"✓ XGBoost available\")\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"✗ XGBoost not available - install with: pip install xgboost\")\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    LIGHTGBM_AVAILABLE = True\n",
    "    print(\"✓ LightGBM available\")\n",
    "except ImportError:\n",
    "    LIGHTGBM_AVAILABLE = False\n",
    "    print(\"✗ LightGBM not available - install with: pip install lightgbm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set:\n",
      "  - Random State: 42\n",
      "  - Test Size: 0.2\n",
      "  - CV Folds: 5\n",
      "  - Min Coach Opportunities: 20\n",
      "  - Number of Features: 31\n"
     ]
    }
   ],
   "source": [
    "# Configuration parameters\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "CV_FOLDS = 5\n",
    "MIN_COACH_OPPORTUNITIES = 20  # Minimum 4th downs for coach ranking\n",
    "\n",
    "# Features to use in modeling\n",
    "FEATURE_COLUMNS = [\n",
    "    # Core situation features\n",
    "    'distance',\n",
    "    'log_distance',\n",
    "    'yards_to_goal',\n",
    "    'period',\n",
    "    \n",
    "    # Time features\n",
    "    'seconds_remaining_game',\n",
    "    'seconds_remaining_half',\n",
    "    \n",
    "    # Score features\n",
    "    'point_differential',\n",
    "    'total_score',\n",
    "    'is_trailing',\n",
    "    'is_leading',\n",
    "    'abs_point_diff',\n",
    "    \n",
    "    # Betting features\n",
    "    'pos_team_spread',\n",
    "    'pos_team_is_underdog',\n",
    "    \n",
    "    # Field position\n",
    "    'in_opponent_territory',\n",
    "    'in_red_zone',\n",
    "    'in_scoring_position',\n",
    "    'goal_to_go',\n",
    "    \n",
    "    # Down and distance categories\n",
    "    'short_yardage',\n",
    "    'medium_yardage',\n",
    "    'long_yardage',\n",
    "    \n",
    "    # Talent features\n",
    "    'talent_gap',\n",
    "    'scaled_talent_gap',\n",
    "    \n",
    "    # Game situation\n",
    "    'late_and_close',\n",
    "    'garbage_time',\n",
    "    'two_minute_drill',\n",
    "    'is_conference_game',\n",
    "    'pos_team_is_home',\n",
    "    \n",
    "    # Historical context\n",
    "    'prev_play_successful',\n",
    "    'prev_4th_down_success_rate',\n",
    "    \n",
    "    # Advanced metrics\n",
    "    'wp_before',\n",
    "    'wp_leverage'\n",
    "]\n",
    "\n",
    "TARGET_COLUMN = 'went_for_it'\n",
    "\n",
    "print(f\"Configuration set:\")\n",
    "print(f\"  - Random State: {RANDOM_STATE}\")\n",
    "print(f\"  - Test Size: {TEST_SIZE}\")\n",
    "print(f\"  - CV Folds: {CV_FOLDS}\")\n",
    "print(f\"  - Min Coach Opportunities: {MIN_COACH_OPPORTUNITIES}\")\n",
    "print(f\"  - Number of Features: {len(FEATURE_COLUMNS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(filepath: str) -> tuple:\n",
    "    \"\"\"Load data and prepare for modeling.\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"LOADING DATA\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    df = pd.read_csv(filepath)\n",
    "    df.dropna(inplace = True)\n",
    "    print(f\"Loaded {len(df):,} records\")\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"\\nTarget distribution:\")\n",
    "    print(f\"  Went for it: {df[TARGET_COLUMN].sum():,} ({df[TARGET_COLUMN].mean()*100:.2f}%)\")\n",
    "    print(f\"  Punt/FG: {(df[TARGET_COLUMN]==0).sum():,} ({(1-df[TARGET_COLUMN].mean())*100:.2f}%)\")\n",
    "    \n",
    "    # Select features that exist in the data\n",
    "    available_features = [f for f in FEATURE_COLUMNS if f in df.columns]\n",
    "    missing_features = [f for f in FEATURE_COLUMNS if f not in df.columns]\n",
    "    \n",
    "    if missing_features:\n",
    "        print(f\"\\nWarning: Missing features: {missing_features}\")\n",
    "    \n",
    "    print(f\"\\nUsing {len(available_features)} features for modeling\")\n",
    "    \n",
    "    # Prepare feature matrix\n",
    "    X = df[available_features].copy()\n",
    "    y = df[TARGET_COLUMN].copy()\n",
    "    \n",
    "    # Handle any remaining NaN values\n",
    "    X = X.dropna()\n",
    "    X.drop(columns=\"log_distance\", inplace=True)\n",
    "    \n",
    "    # Store metadata for later\n",
    "    metadata = df[['id_play', 'game_id', 'year', 'week', 'pos_team', \n",
    "                   'def_pos_team', 'coach_name', 'play_type', 'distance',\n",
    "                   'yards_to_goal', TARGET_COLUMN]].copy()\n",
    "    \n",
    "    return X, y, metadata, available_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING DATA\n",
      "============================================================\n",
      "Loaded 200,056 records\n",
      "\n",
      "Target distribution:\n",
      "  Went for it: 43,151 (21.57%)\n",
      "  Punt/FG: 156,905 (78.43%)\n",
      "\n",
      "Using 31 features for modeling\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "X, y, metadata, feature_names = load_and_preprocess_data('Fourth_Down_Model_Data_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance</th>\n",
       "      <th>yards_to_goal</th>\n",
       "      <th>period</th>\n",
       "      <th>seconds_remaining_game</th>\n",
       "      <th>seconds_remaining_half</th>\n",
       "      <th>point_differential</th>\n",
       "      <th>total_score</th>\n",
       "      <th>is_trailing</th>\n",
       "      <th>is_leading</th>\n",
       "      <th>abs_point_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>scaled_talent_gap</th>\n",
       "      <th>late_and_close</th>\n",
       "      <th>garbage_time</th>\n",
       "      <th>two_minute_drill</th>\n",
       "      <th>is_conference_game</th>\n",
       "      <th>pos_team_is_home</th>\n",
       "      <th>prev_play_successful</th>\n",
       "      <th>prev_4th_down_success_rate</th>\n",
       "      <th>wp_before</th>\n",
       "      <th>wp_leverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>2471</td>\n",
       "      <td>671</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.242744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.390406</td>\n",
       "      <td>0.109594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2275</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.242744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.483306</td>\n",
       "      <td>0.016694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2154</td>\n",
       "      <td>354</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.242744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.547828</td>\n",
       "      <td>0.047828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>211</td>\n",
       "      <td>-7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.242744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.211788</td>\n",
       "      <td>0.288212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1830</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.242744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.699476</td>\n",
       "      <td>0.199476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>-7</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.242744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229629</td>\n",
       "      <td>0.270371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.242744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.802259</td>\n",
       "      <td>0.302259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1619</td>\n",
       "      <td>719</td>\n",
       "      <td>-7</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.242744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144379</td>\n",
       "      <td>0.355621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>1547</td>\n",
       "      <td>647</td>\n",
       "      <td>-14</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.242744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048314</td>\n",
       "      <td>0.451686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>1371</td>\n",
       "      <td>471</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.242744</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.935216</td>\n",
       "      <td>0.435216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance  yards_to_goal  period  seconds_remaining_game  \\\n",
       "0        18             76       1                    2471   \n",
       "1         6             45       1                    2275   \n",
       "2         1             37       1                    2154   \n",
       "3         2             60       1                    2011   \n",
       "4         7             68       1                    1830   \n",
       "5         3             49       2                      75   \n",
       "6         4             81       2                       9   \n",
       "7        18             76       3                    1619   \n",
       "8         6             71       3                    1547   \n",
       "9        16             27       3                    1371   \n",
       "\n",
       "   seconds_remaining_half  point_differential  total_score  is_trailing  \\\n",
       "0                     671                   0            0            0   \n",
       "1                     475                   0            0            0   \n",
       "2                     354                   7            7            0   \n",
       "3                     211                  -7            7            1   \n",
       "4                      30                   7            7            0   \n",
       "5                      75                  -7           21            1   \n",
       "6                       9                   7           21            0   \n",
       "7                     719                  -7           21            1   \n",
       "8                     647                 -14           28            1   \n",
       "9                     471                  14           28            0   \n",
       "\n",
       "   is_leading  abs_point_diff  ...  scaled_talent_gap  late_and_close  \\\n",
       "0           0               0  ...           1.242744               0   \n",
       "1           0               0  ...          -1.242744               0   \n",
       "2           1               7  ...           1.242744               0   \n",
       "3           0               7  ...          -1.242744               0   \n",
       "4           1               7  ...           1.242744               0   \n",
       "5           0               7  ...          -1.242744               0   \n",
       "6           1               7  ...           1.242744               0   \n",
       "7           0               7  ...          -1.242744               0   \n",
       "8           0              14  ...          -1.242744               0   \n",
       "9           1              14  ...           1.242744               0   \n",
       "\n",
       "   garbage_time  two_minute_drill  is_conference_game  pos_team_is_home  \\\n",
       "0             0                 0                   0                 1   \n",
       "1             0                 0                   0                 0   \n",
       "2             0                 0                   0                 1   \n",
       "3             0                 0                   0                 0   \n",
       "4             0                 0                   0                 1   \n",
       "5             0                 1                   0                 0   \n",
       "6             0                 1                   0                 1   \n",
       "7             0                 0                   0                 0   \n",
       "8             0                 0                   0                 0   \n",
       "9             0                 0                   0                 1   \n",
       "\n",
       "   prev_play_successful  prev_4th_down_success_rate  wp_before  wp_leverage  \n",
       "0                     0                         0.5   0.390406     0.109594  \n",
       "1                     0                         0.5   0.483306     0.016694  \n",
       "2                     1                         0.5   0.547828     0.047828  \n",
       "3                     1                         0.5   0.211788     0.288212  \n",
       "4                     1                         1.0   0.699476     0.199476  \n",
       "5                     0                         0.0   0.229629     0.270371  \n",
       "6                     0                         0.5   0.802259     0.302259  \n",
       "7                     0                         0.0   0.144379     0.355621  \n",
       "8                     1                         0.0   0.048314     0.451686  \n",
       "9                     0                         0.5   0.935216     0.435216  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the features\n",
    "print(\"Feature Preview:\")\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>distance</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>7.691121</td>\n",
       "      <td>5.727653</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yards_to_goal</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>50.550731</td>\n",
       "      <td>24.147301</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>2.521984</td>\n",
       "      <td>1.118835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_remaining_game</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>1070.117652</td>\n",
       "      <td>797.900946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>875.000000</td>\n",
       "      <td>1723.000000</td>\n",
       "      <td>3480.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_remaining_half</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>447.343529</td>\n",
       "      <td>272.234881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>447.000000</td>\n",
       "      <td>681.000000</td>\n",
       "      <td>2940.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point_differential</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>-2.016840</td>\n",
       "      <td>15.647403</td>\n",
       "      <td>-104.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_score</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>26.991547</td>\n",
       "      <td>19.981969</td>\n",
       "      <td>-57.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_trailing</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.476217</td>\n",
       "      <td>0.499435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_leading</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.372111</td>\n",
       "      <td>0.483369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abs_point_diff</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>11.190472</td>\n",
       "      <td>11.121224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>104.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_team_spread</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>-2.185441</td>\n",
       "      <td>16.460899</td>\n",
       "      <td>-62.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_team_is_underdog</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.427785</td>\n",
       "      <td>0.494759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_opponent_territory</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.457117</td>\n",
       "      <td>0.498159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_red_zone</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.149638</td>\n",
       "      <td>0.356717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_scoring_position</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.286565</td>\n",
       "      <td>0.452158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goal_to_go</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.037639</td>\n",
       "      <td>0.190323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_yardage</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.267255</td>\n",
       "      <td>0.442528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium_yardage</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.297302</td>\n",
       "      <td>0.457072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_yardage</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.435443</td>\n",
       "      <td>0.495816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talent_gap</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>-15.376100</td>\n",
       "      <td>199.966333</td>\n",
       "      <td>-980.230000</td>\n",
       "      <td>-88.410000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.190000</td>\n",
       "      <td>980.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaled_talent_gap</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>-0.057764</td>\n",
       "      <td>0.764081</td>\n",
       "      <td>-5.131092</td>\n",
       "      <td>-0.340632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225942</td>\n",
       "      <td>5.131092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>late_and_close</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.095803</td>\n",
       "      <td>0.294322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>garbage_time</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.075844</td>\n",
       "      <td>0.264749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two_minute_drill</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.103006</td>\n",
       "      <td>0.303968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_conference_game</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.644115</td>\n",
       "      <td>0.478782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_team_is_home</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.473952</td>\n",
       "      <td>0.499322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_play_successful</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.425696</td>\n",
       "      <td>0.494449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_4th_down_success_rate</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.472605</td>\n",
       "      <td>0.309605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wp_before</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.427367</td>\n",
       "      <td>0.340338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096436</td>\n",
       "      <td>0.399161</td>\n",
       "      <td>0.723405</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wp_leverage</th>\n",
       "      <td>200056.0</td>\n",
       "      <td>0.297117</td>\n",
       "      <td>0.169615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135334</td>\n",
       "      <td>0.321096</td>\n",
       "      <td>0.468373</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count         mean         std         min  \\\n",
       "distance                    200056.0     7.691121    5.727653   -3.000000   \n",
       "yards_to_goal               200056.0    50.550731   24.147301  -17.000000   \n",
       "period                      200056.0     2.521984    1.118835    1.000000   \n",
       "seconds_remaining_game      200056.0  1070.117652  797.900946    0.000000   \n",
       "seconds_remaining_half      200056.0   447.343529  272.234881    0.000000   \n",
       "point_differential          200056.0    -2.016840   15.647403 -104.000000   \n",
       "total_score                 200056.0    26.991547   19.981969  -57.000000   \n",
       "is_trailing                 200056.0     0.476217    0.499435    0.000000   \n",
       "is_leading                  200056.0     0.372111    0.483369    0.000000   \n",
       "abs_point_diff              200056.0    11.190472   11.121224    0.000000   \n",
       "pos_team_spread             200056.0    -2.185441   16.460899  -62.000000   \n",
       "pos_team_is_underdog        200056.0     0.427785    0.494759    0.000000   \n",
       "in_opponent_territory       200056.0     0.457117    0.498159    0.000000   \n",
       "in_red_zone                 200056.0     0.149638    0.356717    0.000000   \n",
       "in_scoring_position         200056.0     0.286565    0.452158    0.000000   \n",
       "goal_to_go                  200056.0     0.037639    0.190323    0.000000   \n",
       "short_yardage               200056.0     0.267255    0.442528    0.000000   \n",
       "medium_yardage              200056.0     0.297302    0.457072    0.000000   \n",
       "long_yardage                200056.0     0.435443    0.495816    0.000000   \n",
       "talent_gap                  200056.0   -15.376100  199.966333 -980.230000   \n",
       "scaled_talent_gap           200056.0    -0.057764    0.764081   -5.131092   \n",
       "late_and_close              200056.0     0.095803    0.294322    0.000000   \n",
       "garbage_time                200056.0     0.075844    0.264749    0.000000   \n",
       "two_minute_drill            200056.0     0.103006    0.303968    0.000000   \n",
       "is_conference_game          200056.0     0.644115    0.478782    0.000000   \n",
       "pos_team_is_home            200056.0     0.473952    0.499322    0.000000   \n",
       "prev_play_successful        200056.0     0.425696    0.494449    0.000000   \n",
       "prev_4th_down_success_rate  200056.0     0.472605    0.309605    0.000000   \n",
       "wp_before                   200056.0     0.427367    0.340338    0.000000   \n",
       "wp_leverage                 200056.0     0.297117    0.169615    0.000000   \n",
       "\n",
       "                                   25%         50%          75%          max  \n",
       "distance                      3.000000    7.000000    10.000000    84.000000  \n",
       "yards_to_goal                32.000000   54.000000    70.000000   100.000000  \n",
       "period                        2.000000    2.000000     4.000000     9.000000  \n",
       "seconds_remaining_game      393.000000  875.000000  1723.000000  3480.000000  \n",
       "seconds_remaining_half      207.000000  447.000000   681.000000  2940.000000  \n",
       "point_differential          -10.000000    0.000000     7.000000   100.000000  \n",
       "total_score                  10.000000   24.000000    41.000000   180.000000  \n",
       "is_trailing                   0.000000    0.000000     1.000000     1.000000  \n",
       "is_leading                    0.000000    0.000000     1.000000     1.000000  \n",
       "abs_point_diff                3.000000    7.000000    16.000000   104.000000  \n",
       "pos_team_spread             -12.000000   -2.000000     7.000000    62.000000  \n",
       "pos_team_is_underdog          0.000000    0.000000     1.000000     1.000000  \n",
       "in_opponent_territory         0.000000    0.000000     1.000000     1.000000  \n",
       "in_red_zone                   0.000000    0.000000     0.000000     1.000000  \n",
       "in_scoring_position           0.000000    0.000000     1.000000     1.000000  \n",
       "goal_to_go                    0.000000    0.000000     0.000000     1.000000  \n",
       "short_yardage                 0.000000    0.000000     1.000000     1.000000  \n",
       "medium_yardage                0.000000    0.000000     1.000000     1.000000  \n",
       "long_yardage                  0.000000    0.000000     1.000000     1.000000  \n",
       "talent_gap                  -88.410000    0.000000    59.190000   980.230000  \n",
       "scaled_talent_gap            -0.340632    0.000000     0.225942     5.131092  \n",
       "late_and_close                0.000000    0.000000     0.000000     1.000000  \n",
       "garbage_time                  0.000000    0.000000     0.000000     1.000000  \n",
       "two_minute_drill              0.000000    0.000000     0.000000     1.000000  \n",
       "is_conference_game            0.000000    1.000000     1.000000     1.000000  \n",
       "pos_team_is_home              0.000000    0.000000     1.000000     1.000000  \n",
       "prev_play_successful          0.000000    0.000000     1.000000     1.000000  \n",
       "prev_4th_down_success_rate    0.333333    0.500000     0.500000     1.000000  \n",
       "wp_before                     0.096436    0.399161     0.723405     1.000000  \n",
       "wp_leverage                   0.135334    0.321096     0.468373     0.500000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for any data issues\n",
    "print(\"Feature Statistics:\")\n",
    "X.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split:\n",
      "  Training: 160,044 samples (80.0%)\n",
      "  Testing: 40,012 samples (20.0%)\n",
      "\n",
      "Target balance in training: 21.57% went for it\n",
      "Target balance in testing: 21.57% went for it\n"
     ]
    }
   ],
   "source": [
    "def split_data(X: pd.DataFrame, y: pd.Series) -> tuple:\n",
    "    \"\"\"Split data into train and test sets.\"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=TEST_SIZE, \n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y\n",
    "    )\n",
    "    \n",
    "    print(f\"Data split:\")\n",
    "    print(f\"  Training: {len(X_train):,} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "    print(f\"  Testing: {len(X_test):,} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "    print(f\"\\nTarget balance in training: {y_train.mean()*100:.2f}% went for it\")\n",
    "    print(f\"Target balance in testing: {y_test.mean()*100:.2f}% went for it\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to evaluate: 10\n",
      "  • Logistic Regression\n",
      "  • Random Forest\n",
      "  • Gradient Boosting\n",
      "  • Extra Trees\n",
      "  • AdaBoost\n",
      "  • Decision Tree\n",
      "  • K-Nearest Neighbors\n",
      "  • Naive Bayes\n",
      "  • XGBoost\n",
      "  • LightGBM\n"
     ]
    }
   ],
   "source": [
    "def get_models() -> dict:\n",
    "    \"\"\"Define all models to test.\"\"\"\n",
    "    \n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(\n",
    "            random_state=RANDOM_STATE, max_iter=1000\n",
    "        ),\n",
    "        'Random Forest': RandomForestClassifier(\n",
    "            n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1\n",
    "        ),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(\n",
    "            n_estimators=100, random_state=RANDOM_STATE\n",
    "        ),\n",
    "        'Extra Trees': ExtraTreesClassifier(\n",
    "            n_estimators=100, random_state=RANDOM_STATE, n_jobs=-1\n",
    "        ),\n",
    "        'AdaBoost': AdaBoostClassifier(\n",
    "            n_estimators=100, random_state=RANDOM_STATE\n",
    "        ),\n",
    "        'Decision Tree': DecisionTreeClassifier(\n",
    "            random_state=RANDOM_STATE\n",
    "        ),\n",
    "        'K-Nearest Neighbors': KNeighborsClassifier(\n",
    "            n_neighbors=5, n_jobs=-1\n",
    "        ),\n",
    "        'Naive Bayes': GaussianNB(),\n",
    "    }\n",
    "    \n",
    "    # Add XGBoost if available\n",
    "    if XGBOOST_AVAILABLE:\n",
    "        models['XGBoost'] = XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=RANDOM_STATE,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    \n",
    "    # Add LightGBM if available\n",
    "    if LIGHTGBM_AVAILABLE:\n",
    "        models['LightGBM'] = LGBMClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=RANDOM_STATE,\n",
    "            verbose=-1,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    \n",
    "    print(f\"Models to evaluate: {len(models)}\")\n",
    "    for name in models.keys():\n",
    "        print(f\"  • {name}\")\n",
    "    \n",
    "    return models\n",
    "\n",
    "models = get_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models: dict, X_train: pd.DataFrame, X_test: pd.DataFrame,\n",
    "                   y_train: pd.Series, y_test: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"Train and evaluate all models.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"MODEL EVALUATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Scale features for models that benefit from it\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    results = []\n",
    "    trained_models = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n▶ Training {name}...\")\n",
    "        \n",
    "        try:\n",
    "            # Use scaled data for certain models\n",
    "            if name in ['Logistic Regression', 'K-Nearest Neighbors', 'SVM']:\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                y_pred = model.predict(X_test_scaled)\n",
    "                y_prob = model.predict_proba(X_test_scaled)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            roc_auc = roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
    "            \n",
    "            # Cross-validation score\n",
    "            cv_scores = cross_val_score(model, X_train, y_train, cv=CV_FOLDS, scoring='f1')\n",
    "            cv_mean = cv_scores.mean()\n",
    "            cv_std = cv_scores.std()\n",
    "            \n",
    "            results.append({\n",
    "                'Model': name,\n",
    "                'Accuracy': accuracy,\n",
    "                'F1-Score': f1,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'ROC-AUC': roc_auc,\n",
    "                'CV F1 Mean': cv_mean,\n",
    "                'CV F1 Std': cv_std\n",
    "            })\n",
    "            \n",
    "            trained_models[name] = model\n",
    "            \n",
    "            print(f\"  ✓ Accuracy: {accuracy:.4f} | F1: {f1:.4f} | CV F1: {cv_mean:.4f} (±{cv_std:.4f})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error training {name}: {e}\")\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('F1-Score', ascending=False)\n",
    "    \n",
    "    return results_df, trained_models, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL EVALUATION\n",
      "============================================================\n",
      "\n",
      "▶ Training Logistic Regression...\n",
      "  ✓ Accuracy: 0.8464 | F1: 0.5895 | CV F1: 0.5776 (±0.0076)\n",
      "\n",
      "▶ Training Random Forest...\n",
      "  ✓ Accuracy: 0.8964 | F1: 0.7459 | CV F1: 0.7347 (±0.0039)\n",
      "\n",
      "▶ Training Gradient Boosting...\n",
      "  ✓ Accuracy: 0.8770 | F1: 0.6829 | CV F1: 0.6774 (±0.0052)\n",
      "\n",
      "▶ Training Extra Trees...\n",
      "  ✓ Accuracy: 0.8920 | F1: 0.7324 | CV F1: 0.7194 (±0.0046)\n",
      "\n",
      "▶ Training AdaBoost...\n",
      "  ✓ Accuracy: 0.8539 | F1: 0.6079 | CV F1: 0.6076 (±0.0034)\n",
      "\n",
      "▶ Training Decision Tree...\n",
      "  ✓ Accuracy: 0.8495 | F1: 0.6510 | CV F1: 0.6380 (±0.0028)\n",
      "\n",
      "▶ Training K-Nearest Neighbors...\n",
      "  ✓ Accuracy: 0.8498 | F1: 0.6258 | CV F1: 0.4114 (±0.0025)\n",
      "\n",
      "▶ Training Naive Bayes...\n",
      "  ✓ Accuracy: 0.7819 | F1: 0.5495 | CV F1: 0.5449 (±0.0049)\n",
      "\n",
      "▶ Training XGBoost...\n",
      "  ✓ Accuracy: 0.8903 | F1: 0.7331 | CV F1: 0.7291 (±0.0066)\n",
      "\n",
      "▶ Training LightGBM...\n",
      "  ✓ Accuracy: 0.8873 | F1: 0.7261 | CV F1: 0.7238 (±0.0068)\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate all models\n",
    "results_df, trained_models, scaler = evaluate_models(\n",
    "    models, X_train, X_test, y_train, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL COMPARISON RESULTS\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC-AUC</th>\n",
       "      <th>CV F1 Mean</th>\n",
       "      <th>CV F1 Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.7459</td>\n",
       "      <td>0.7915</td>\n",
       "      <td>0.7052</td>\n",
       "      <td>0.9356</td>\n",
       "      <td>0.7347</td>\n",
       "      <td>0.0039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.8903</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.7712</td>\n",
       "      <td>0.6986</td>\n",
       "      <td>0.9319</td>\n",
       "      <td>0.7291</td>\n",
       "      <td>0.0066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>0.8920</td>\n",
       "      <td>0.7324</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>0.6849</td>\n",
       "      <td>0.9330</td>\n",
       "      <td>0.7194</td>\n",
       "      <td>0.0046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.8873</td>\n",
       "      <td>0.7261</td>\n",
       "      <td>0.7633</td>\n",
       "      <td>0.6924</td>\n",
       "      <td>0.9301</td>\n",
       "      <td>0.7238</td>\n",
       "      <td>0.0068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.8770</td>\n",
       "      <td>0.6829</td>\n",
       "      <td>0.7691</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>0.6774</td>\n",
       "      <td>0.0052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.8495</td>\n",
       "      <td>0.6510</td>\n",
       "      <td>0.6511</td>\n",
       "      <td>0.6509</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.6380</td>\n",
       "      <td>0.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.8498</td>\n",
       "      <td>0.6258</td>\n",
       "      <td>0.6762</td>\n",
       "      <td>0.5824</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.4114</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.8539</td>\n",
       "      <td>0.6079</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.8909</td>\n",
       "      <td>0.6076</td>\n",
       "      <td>0.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>0.5895</td>\n",
       "      <td>0.6961</td>\n",
       "      <td>0.5112</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>0.5776</td>\n",
       "      <td>0.0076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.7819</td>\n",
       "      <td>0.5495</td>\n",
       "      <td>0.4955</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.8187</td>\n",
       "      <td>0.5449</td>\n",
       "      <td>0.0049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Accuracy F1-Score Precision  Recall ROC-AUC CV F1 Mean  \\\n",
       "1        Random Forest   0.8964   0.7459    0.7915  0.7052  0.9356     0.7347   \n",
       "8              XGBoost   0.8903   0.7331    0.7712  0.6986  0.9319     0.7291   \n",
       "3          Extra Trees   0.8920   0.7324    0.7869  0.6849  0.9330     0.7194   \n",
       "9             LightGBM   0.8873   0.7261    0.7633  0.6924  0.9301     0.7238   \n",
       "2    Gradient Boosting   0.8770   0.6829    0.7691  0.6140  0.9190     0.6774   \n",
       "5        Decision Tree   0.8495   0.6510    0.6511  0.6509  0.7778     0.6380   \n",
       "6  K-Nearest Neighbors   0.8498   0.6258    0.6762  0.5824  0.8562     0.4114   \n",
       "4             AdaBoost   0.8539   0.6079    0.7220  0.5250  0.8909     0.6076   \n",
       "0  Logistic Regression   0.8464   0.5895    0.6961  0.5112  0.8748     0.5776   \n",
       "7          Naive Bayes   0.7819   0.5495    0.4955  0.6168  0.8187     0.5449   \n",
       "\n",
       "  CV F1 Std  \n",
       "1    0.0039  \n",
       "8    0.0066  \n",
       "3    0.0046  \n",
       "9    0.0068  \n",
       "2    0.0052  \n",
       "5    0.0028  \n",
       "6    0.0025  \n",
       "4    0.0034  \n",
       "0    0.0076  \n",
       "7    0.0049  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display model comparison\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL COMPARISON RESULTS\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "# Format for display\n",
    "display_df = results_df.copy()\n",
    "for col in ['Accuracy', 'F1-Score', 'Precision', 'Recall', 'ROC-AUC', 'CV F1 Mean', 'CV F1 Std']:\n",
    "    if col in display_df.columns:\n",
    "        display_df[col] = display_df[col].apply(lambda x: f\"{x:.4f}\" if pd.notnull(x) else \"N/A\")\n",
    "\n",
    "display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BEST MODEL: Random Forest\n",
      "============================================================\n",
      "  Accuracy:  0.8964\n",
      "  F1-Score:  0.7459\n",
      "  Precision: 0.7915\n",
      "  Recall:    0.7052\n",
      "  ROC-AUC:   0.9356\n"
     ]
    }
   ],
   "source": [
    "# Identify best model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"BEST MODEL: {best_model_name}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Accuracy:  {results_df.iloc[0]['Accuracy']:.4f}\")\n",
    "print(f\"  F1-Score:  {results_df.iloc[0]['F1-Score']:.4f}\")\n",
    "print(f\"  Precision: {results_df.iloc[0]['Precision']:.4f}\")\n",
    "print(f\"  Recall:    {results_df.iloc[0]['Recall']:.4f}\")\n",
    "print(f\"  ROC-AUC:   {results_df.iloc[0]['ROC-AUC']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save initial results\n",
    "results_df.to_csv('model_comparison_results.csv', index=False)\n",
    "print(\"✓ Saved: model_comparison_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_grid(model_name: str) -> dict:\n",
    "    \"\"\"Get hyperparameter grid for the specified model.\"\"\"\n",
    "    \n",
    "    param_grids = {\n",
    "        'XGBoost': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [3, 5, 7, 9],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'subsample': [0.8, 0.9, 1.0],\n",
    "            'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "            'min_child_weight': [1, 3, 5]\n",
    "        },\n",
    "        'LightGBM': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [3, 5, 7, -1],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'num_leaves': [31, 50, 100],\n",
    "            'subsample': [0.8, 0.9, 1.0],\n",
    "            'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "        },\n",
    "        'Random Forest': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [10, 20, 30, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'max_features': ['sqrt', 'log2', None]\n",
    "        },\n",
    "        'Gradient Boosting': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'subsample': [0.8, 0.9, 1.0],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        },\n",
    "        'Logistic Regression': {\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear', 'saga']\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return param_grids.get(model_name, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(model_name: str, model, X_train: pd.DataFrame, y_train: pd.Series,\n",
    "               scaler: StandardScaler = None) -> tuple:\n",
    "    \"\"\"Perform hyperparameter tuning on the best model.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"HYPERPARAMETER TUNING: {model_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    param_grid = get_param_grid(model_name)\n",
    "    \n",
    "    if not param_grid:\n",
    "        print(f\"No hyperparameter grid defined for {model_name}\")\n",
    "        print(\"Returning original model...\")\n",
    "        return model, {}\n",
    "    \n",
    "    # Prepare data\n",
    "    if model_name in ['Logistic Regression'] and scaler is not None:\n",
    "        X_train_tuning = scaler.fit_transform(X_train)\n",
    "    else:\n",
    "        X_train_tuning = X_train\n",
    "    \n",
    "    # Create new model instance for tuning\n",
    "    if model_name == 'XGBoost' and XGBOOST_AVAILABLE:\n",
    "        base_model = XGBClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    elif model_name == 'LightGBM' and LIGHTGBM_AVAILABLE:\n",
    "        base_model = LGBMClassifier(\n",
    "            random_state=RANDOM_STATE,\n",
    "            verbose=-1,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    elif model_name == 'Random Forest':\n",
    "        base_model = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    elif model_name == 'Gradient Boosting':\n",
    "        base_model = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "    elif model_name == 'Logistic Regression':\n",
    "        base_model = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
    "    else:\n",
    "        print(f\"Using pre-trained model for {model_name}\")\n",
    "        return model, {}\n",
    "    \n",
    "    # Use smaller grid for faster tuning\n",
    "    reduced_grid = {k: v[:3] if len(v) > 3 else v for k, v in param_grid.items()}\n",
    "    \n",
    "    print(f\"\\nSearching {len(reduced_grid)} parameters...\")\n",
    "    print(f\"Grid: {reduced_grid}\")\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        base_model,\n",
    "        reduced_grid,\n",
    "        cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE),\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_tuning, y_train)\n",
    "    \n",
    "    print(f\"\\n✓ Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"✓ Best CV F1-Score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    return grid_search.best_estimator_, grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HYPERPARAMETER TUNING: Random Forest\n",
      "============================================================\n",
      "\n",
      "Searching 5 parameters...\n",
      "Grid: {'n_estimators': [100, 200, 300], 'max_depth': [10, 20, 30], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'max_features': ['sqrt', 'log2', None]}\n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "\n",
      "✓ Best parameters: {'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "✓ Best CV F1-Score: 0.7319\n"
     ]
    }
   ],
   "source": [
    "# Tune the best model\n",
    "tuned_model, best_params = tune_model(\n",
    "    best_model_name, best_model, X_train, y_train, scaler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_final_model(model, X_test: pd.DataFrame, y_test: pd.Series,\n",
    "                         feature_names: list, scaler: StandardScaler = None,\n",
    "                         model_name: str = \"Model\") -> dict:\n",
    "    \"\"\"Comprehensive evaluation of the final tuned model.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"FINAL MODEL EVALUATION: {model_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Prepare test data\n",
    "    if model_name in ['Logistic Regression'] and scaler is not None:\n",
    "        X_test_eval = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_test_eval = X_test\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_eval)\n",
    "    y_prob = model.predict_proba(X_test_eval)[:, 1]\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "    \n",
    "    print(f\"\\nFinal Metrics:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  ROC-AUC:   {roc_auc:.4f}\")\n",
    "    \n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Punt/FG', 'Go For It']))\n",
    "    \n",
    "    print(f\"Confusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"  [[TN={cm[0,0]:,}  FP={cm[0,1]:,}]\")\n",
    "    print(f\"   [FN={cm[1,0]:,}  TP={cm[1,1]:,}]]\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'roc_auc': roc_auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL MODEL EVALUATION: Random Forest\n",
      "============================================================\n",
      "\n",
      "Final Metrics:\n",
      "  Accuracy:  0.8967\n",
      "  F1-Score:  0.7470\n",
      "  Precision: 0.7916\n",
      "  Recall:    0.7071\n",
      "  ROC-AUC:   0.9372\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Punt/FG       0.92      0.95      0.94     31382\n",
      "   Go For It       0.79      0.71      0.75      8630\n",
      "\n",
      "    accuracy                           0.90     40012\n",
      "   macro avg       0.86      0.83      0.84     40012\n",
      "weighted avg       0.89      0.90      0.89     40012\n",
      "\n",
      "Confusion Matrix:\n",
      "  [[TN=29,776  FP=1,606]\n",
      "   [FN=2,528  TP=6,102]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final tuned model\n",
    "final_metrics = evaluate_final_model(\n",
    "    tuned_model, X_test, y_test, feature_names, scaler, best_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FEATURE IMPORTANCES\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFEATURE IMPORTANCES\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m importance_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFeature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImportance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtuned_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_importances_\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTop 15 Most Important Features:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m importance_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m15\u001b[39m)\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# Feature importance (if available)\n",
    "if hasattr(tuned_model, 'feature_importances_'):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FEATURE IMPORTANCES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': tuned_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 15 Most Important Features:\")\n",
    "    for i, row in importance_df.head(15).iterrows():\n",
    "        bar = \"█\" * int(row['Importance'] * 50)\n",
    "        print(f\"  {row['Feature']:<30} {row['Importance']:.4f} {bar}\")\n",
    "    \n",
    "    importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate Aggression Over Expectation (AOE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aggression_scores(model, X: pd.DataFrame, metadata: pd.DataFrame,\n",
    "                                feature_names: list, scaler: StandardScaler = None,\n",
    "                                model_name: str = \"Model\") -> pd.DataFrame:\n",
    "    \"\"\"Calculate Aggression Over Expectation for each coach.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CALCULATING AGGRESSION OVER EXPECTATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Prepare full data for prediction\n",
    "    if model_name in ['Logistic Regression'] and scaler is not None:\n",
    "        X_pred = scaler.transform(X)\n",
    "    else:\n",
    "        X_pred = X\n",
    "    \n",
    "    # Get predictions for all plays\n",
    "    predictions = model.predict(X_pred)\n",
    "    probabilities = model.predict_proba(X_pred)[:, 1]\n",
    "    \n",
    "    # Add predictions to metadata\n",
    "    results = metadata.copy()\n",
    "    results['predicted_go'] = predictions\n",
    "    results['predicted_prob'] = probabilities\n",
    "    results['actual_go'] = results['went_for_it']\n",
    "    \n",
    "    # Calculate play-level difference\n",
    "    results['go_over_expected'] = results['actual_go'] - results['predicted_go']\n",
    "    results['go_over_expected_prob'] = results['actual_go'] - results['predicted_prob']\n",
    "    \n",
    "    print(f\"\\nPredictions generated for {len(results):,} plays\")\n",
    "    \n",
    "    # Aggregate by coach\n",
    "    coach_aggression = results.groupby('coach_name').agg({\n",
    "        'actual_go': ['sum', 'mean', 'count'],\n",
    "        'predicted_go': ['sum', 'mean'],\n",
    "        'predicted_prob': ['sum', 'mean'],\n",
    "        'go_over_expected': ['sum', 'mean'],\n",
    "        'go_over_expected_prob': ['sum', 'mean'],\n",
    "        'pos_team': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'Unknown',\n",
    "        'year': ['min', 'max']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten column names\n",
    "    coach_aggression.columns = [\n",
    "        'coach_name',\n",
    "        'total_go_for_it', 'actual_go_rate', 'total_opportunities',\n",
    "        'expected_go_for_it', 'expected_go_rate',\n",
    "        'expected_go_prob_sum', 'expected_go_prob_rate',\n",
    "        'go_over_expected_sum', 'go_over_expected_rate',\n",
    "        'go_over_expected_prob_sum', 'go_over_expected_prob_rate',\n",
    "        'primary_team', 'first_year', 'last_year'\n",
    "    ]\n",
    "    \n",
    "    # Calculate Aggression Over Expectation (AOE)\n",
    "    coach_aggression['aggression_over_expected'] = (\n",
    "        coach_aggression['actual_go_rate'] - coach_aggression['expected_go_rate']\n",
    "    )\n",
    "    \n",
    "    # Probability-based version\n",
    "    coach_aggression['aggression_over_expected_prob'] = (\n",
    "        coach_aggression['actual_go_rate'] - coach_aggression['expected_go_prob_rate']\n",
    "    )\n",
    "    \n",
    "    # Filter to coaches with minimum opportunities\n",
    "    coach_aggression_filtered = coach_aggression[\n",
    "        coach_aggression['total_opportunities'] >= MIN_COACH_OPPORTUNITIES\n",
    "    ].copy()\n",
    "    \n",
    "    # Sort by aggression\n",
    "    coach_aggression_filtered = coach_aggression_filtered.sort_values(\n",
    "        'aggression_over_expected', ascending=False\n",
    "    )\n",
    "    \n",
    "    # Add rank\n",
    "    coach_aggression_filtered['aggression_rank'] = range(1, len(coach_aggression_filtered) + 1)\n",
    "    \n",
    "    print(f\"\\nCoaches with {MIN_COACH_OPPORTUNITIES}+ opportunities: {len(coach_aggression_filtered)}\")\n",
    "    \n",
    "    return coach_aggression_filtered, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CALCULATING AGGRESSION OVER EXPECTATION\n",
      "============================================================\n",
      "\n",
      "Predictions generated for 200,056 plays\n",
      "\n",
      "Coaches with 20+ opportunities: 367\n"
     ]
    }
   ],
   "source": [
    "# Calculate aggression scores\n",
    "coach_aggression, play_results = calculate_aggression_scores(\n",
    "    tuned_model, X, metadata, feature_names, scaler, best_model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TOP 10 MOST AGGRESSIVE COACHES\n",
      "================================================================================\n",
      " 1. Willie Simmons            (Florida International) Opps:  118 | Actual: 0.254 | Expected: 0.203 | AOE: +0.051\n",
      " 2. Joe Harasymiak            (Massachusetts       ) Opps:  125 | Actual: 0.224 | Expected: 0.176 | AOE: +0.048\n",
      " 3. Jason Eck                 (New Mexico          ) Opps:   95 | Actual: 0.337 | Expected: 0.295 | AOE: +0.042\n",
      " 4. Joey McGuire              (Texas Tech          ) Opps:  412 | Actual: 0.303 | Expected: 0.265 | AOE: +0.039\n",
      " 5. Lane Kiffin               (Ole Miss            ) Opps:  850 | Actual: 0.321 | Expected: 0.285 | AOE: +0.036\n",
      " 6. Dan Lanning               (Oregon              ) Opps:  301 | Actual: 0.306 | Expected: 0.272 | AOE: +0.033\n",
      " 7. Mike London               (Virginia            ) Opps:   95 | Actual: 0.158 | Expected: 0.126 | AOE: +0.032\n",
      " 8. Trent Dilfer              (UAB                 ) Opps:  288 | Actual: 0.323 | Expected: 0.292 | AOE: +0.031\n",
      " 9. Dave Aranda               (Baylor              ) Opps:  593 | Actual: 0.373 | Expected: 0.342 | AOE: +0.030\n",
      "10. Charles Kelly             (Jacksonville State  ) Opps:  102 | Actual: 0.235 | Expected: 0.206 | AOE: +0.029\n"
     ]
    }
   ],
   "source": [
    "# Display Top 10 Most Aggressive Coaches\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TOP 10 MOST AGGRESSIVE COACHES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "top10 = coach_aggression.head(10)[[\n",
    "    'aggression_rank', 'coach_name', 'primary_team', 'total_opportunities',\n",
    "    'actual_go_rate', 'expected_go_rate', 'aggression_over_expected'\n",
    "]]\n",
    "\n",
    "for _, row in top10.iterrows():\n",
    "    print(f\"{row['aggression_rank']:2}. {row['coach_name']:<25} ({row['primary_team']:<20}) \"\n",
    "          f\"Opps: {row['total_opportunities']:4} | \"\n",
    "          f\"Actual: {row['actual_go_rate']:.3f} | \"\n",
    "          f\"Expected: {row['expected_go_rate']:.3f} | \"\n",
    "          f\"AOE: {row['aggression_over_expected']:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TOP 10 MOST CONSERVATIVE COACHES\n",
      "================================================================================\n",
      "367. Scott Shafer              (Syracuse            ) Opps:  107 | Actual: 0.131 | Expected: 0.159 | AOE: -0.028\n",
      "366. David Bailiff             (Rice                ) Opps:  291 | Actual: 0.162 | Expected: 0.186 | AOE: -0.024\n",
      "365. Ryan Beard                (Missouri State      ) Opps:   93 | Actual: 0.140 | Expected: 0.161 | AOE: -0.022\n",
      "364. Urban Meyer               (Ohio State          ) Opps:  362 | Actual: 0.213 | Expected: 0.232 | AOE: -0.019\n",
      "363. Tony Gibson               (Marshall            ) Opps:  108 | Actual: 0.139 | Expected: 0.157 | AOE: -0.019\n",
      "362. Lovie Smith               (Illinois            ) Opps:  483 | Actual: 0.133 | Expected: 0.149 | AOE: -0.017\n",
      "361. Gary Patterson            (TCU                 ) Opps:  696 | Actual: 0.135 | Expected: 0.148 | AOE: -0.013\n",
      "360. Nick Saban                (Alabama             ) Opps:  712 | Actual: 0.170 | Expected: 0.183 | AOE: -0.013\n",
      "359. Mark Richt                (Miami               ) Opps:  398 | Actual: 0.138 | Expected: 0.151 | AOE: -0.013\n",
      "358. Karl Dorrell              (Colorado            ) Opps:  251 | Actual: 0.207 | Expected: 0.219 | AOE: -0.012\n"
     ]
    }
   ],
   "source": [
    "# Display Top 10 Most Conservative Coaches\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TOP 10 MOST CONSERVATIVE COACHES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "bottom10 = coach_aggression.tail(10)[[\n",
    "    'aggression_rank', 'coach_name', 'primary_team', 'total_opportunities',\n",
    "    'actual_go_rate', 'expected_go_rate', 'aggression_over_expected'\n",
    "]].iloc[::-1]\n",
    "\n",
    "for _, row in bottom10.iterrows():\n",
    "    print(f\"{row['aggression_rank']:2}. {row['coach_name']:<25} ({row['primary_team']:<20}) \"\n",
    "          f\"Opps: {row['total_opportunities']:4} | \"\n",
    "          f\"Actual: {row['actual_go_rate']:.3f} | \"\n",
    "          f\"Expected: {row['expected_go_rate']:.3f} | \"\n",
    "          f\"AOE: {row['aggression_over_expected']:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FULL AGGRESSION RANKINGS\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggression_rank</th>\n",
       "      <th>coach_name</th>\n",
       "      <th>primary_team</th>\n",
       "      <th>total_opportunities</th>\n",
       "      <th>actual_go_rate</th>\n",
       "      <th>expected_go_rate</th>\n",
       "      <th>aggression_over_expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>1</td>\n",
       "      <td>Willie Simmons</td>\n",
       "      <td>Florida International</td>\n",
       "      <td>118</td>\n",
       "      <td>0.254237</td>\n",
       "      <td>0.203390</td>\n",
       "      <td>0.050847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2</td>\n",
       "      <td>Joe Harasymiak</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>125</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>3</td>\n",
       "      <td>Jason Eck</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>95</td>\n",
       "      <td>0.336842</td>\n",
       "      <td>0.294737</td>\n",
       "      <td>0.042105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>4</td>\n",
       "      <td>Joey McGuire</td>\n",
       "      <td>Texas Tech</td>\n",
       "      <td>412</td>\n",
       "      <td>0.303398</td>\n",
       "      <td>0.264563</td>\n",
       "      <td>0.038835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>5</td>\n",
       "      <td>Lane Kiffin</td>\n",
       "      <td>Ole Miss</td>\n",
       "      <td>850</td>\n",
       "      <td>0.321176</td>\n",
       "      <td>0.284706</td>\n",
       "      <td>0.036471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6</td>\n",
       "      <td>Dan Lanning</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>301</td>\n",
       "      <td>0.305648</td>\n",
       "      <td>0.272425</td>\n",
       "      <td>0.033223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>7</td>\n",
       "      <td>Mike London</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>95</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.126316</td>\n",
       "      <td>0.031579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>8</td>\n",
       "      <td>Trent Dilfer</td>\n",
       "      <td>UAB</td>\n",
       "      <td>288</td>\n",
       "      <td>0.322917</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>9</td>\n",
       "      <td>Dave Aranda</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>593</td>\n",
       "      <td>0.372681</td>\n",
       "      <td>0.342327</td>\n",
       "      <td>0.030354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>10</td>\n",
       "      <td>Charles Kelly</td>\n",
       "      <td>Jacksonville State</td>\n",
       "      <td>102</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>11</td>\n",
       "      <td>Fran Brown</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>206</td>\n",
       "      <td>0.310680</td>\n",
       "      <td>0.281553</td>\n",
       "      <td>0.029126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>12</td>\n",
       "      <td>Trent Bray</td>\n",
       "      <td>Oregon State</td>\n",
       "      <td>209</td>\n",
       "      <td>0.320574</td>\n",
       "      <td>0.291866</td>\n",
       "      <td>0.028708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>13</td>\n",
       "      <td>Scott Abell</td>\n",
       "      <td>Rice</td>\n",
       "      <td>113</td>\n",
       "      <td>0.265487</td>\n",
       "      <td>0.238938</td>\n",
       "      <td>0.026549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>Bill O'Brien</td>\n",
       "      <td>Boston College</td>\n",
       "      <td>199</td>\n",
       "      <td>0.316583</td>\n",
       "      <td>0.291457</td>\n",
       "      <td>0.025126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>15</td>\n",
       "      <td>Kenny Dillingham</td>\n",
       "      <td>Arizona State</td>\n",
       "      <td>325</td>\n",
       "      <td>0.304615</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.024615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>16</td>\n",
       "      <td>Charlie Partridge</td>\n",
       "      <td>Florida Atlantic</td>\n",
       "      <td>214</td>\n",
       "      <td>0.228972</td>\n",
       "      <td>0.205607</td>\n",
       "      <td>0.023364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Art Briles</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>96</td>\n",
       "      <td>0.364583</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>18</td>\n",
       "      <td>Matt Drinkall</td>\n",
       "      <td>Central Michigan</td>\n",
       "      <td>98</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.020408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>19</td>\n",
       "      <td>Jeff Choate</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>197</td>\n",
       "      <td>0.279188</td>\n",
       "      <td>0.258883</td>\n",
       "      <td>0.020305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>20</td>\n",
       "      <td>Paul Petrino</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>299</td>\n",
       "      <td>0.207358</td>\n",
       "      <td>0.187291</td>\n",
       "      <td>0.020067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>21</td>\n",
       "      <td>Jeff Monken</td>\n",
       "      <td>Army</td>\n",
       "      <td>804</td>\n",
       "      <td>0.430348</td>\n",
       "      <td>0.410448</td>\n",
       "      <td>0.019900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>22</td>\n",
       "      <td>Tim Lappano</td>\n",
       "      <td>Georgia State</td>\n",
       "      <td>102</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>23</td>\n",
       "      <td>Scotty Walden</td>\n",
       "      <td>UTEP</td>\n",
       "      <td>312</td>\n",
       "      <td>0.262821</td>\n",
       "      <td>0.243590</td>\n",
       "      <td>0.019231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>24</td>\n",
       "      <td>Clark Lea</td>\n",
       "      <td>Vanderbilt</td>\n",
       "      <td>477</td>\n",
       "      <td>0.243187</td>\n",
       "      <td>0.224319</td>\n",
       "      <td>0.018868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>25</td>\n",
       "      <td>Butch Davis</td>\n",
       "      <td>Florida International</td>\n",
       "      <td>432</td>\n",
       "      <td>0.201389</td>\n",
       "      <td>0.182870</td>\n",
       "      <td>0.018519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     aggression_rank         coach_name           primary_team  \\\n",
       "363                1     Willie Simmons  Florida International   \n",
       "166                2     Joe Harasymiak          Massachusetts   \n",
       "139                3          Jason Eck             New Mexico   \n",
       "170                4       Joey McGuire             Texas Tech   \n",
       "201                5        Lane Kiffin               Ole Miss   \n",
       "75                 6        Dan Lanning                 Oregon   \n",
       "245                7        Mike London               Virginia   \n",
       "347                8       Trent Dilfer                    UAB   \n",
       "83                 9        Dave Aranda                 Baylor   \n",
       "53                10      Charles Kelly     Jacksonville State   \n",
       "112               11         Fran Brown               Syracuse   \n",
       "346               12         Trent Bray           Oregon State   \n",
       "297               13        Scott Abell                   Rice   \n",
       "11                14       Bill O'Brien         Boston College   \n",
       "187               15   Kenny Dillingham          Arizona State   \n",
       "54                16  Charlie Partridge       Florida Atlantic   \n",
       "4                 17         Art Briles                 Baylor   \n",
       "227               18      Matt Drinkall       Central Michigan   \n",
       "146               19        Jeff Choate                 Nevada   \n",
       "267               20       Paul Petrino                  Idaho   \n",
       "149               21        Jeff Monken                   Army   \n",
       "329               22        Tim Lappano          Georgia State   \n",
       "302               23      Scotty Walden                   UTEP   \n",
       "65                24          Clark Lea             Vanderbilt   \n",
       "43                25        Butch Davis  Florida International   \n",
       "\n",
       "     total_opportunities  actual_go_rate  expected_go_rate  \\\n",
       "363                  118        0.254237          0.203390   \n",
       "166                  125        0.224000          0.176000   \n",
       "139                   95        0.336842          0.294737   \n",
       "170                  412        0.303398          0.264563   \n",
       "201                  850        0.321176          0.284706   \n",
       "75                   301        0.305648          0.272425   \n",
       "245                   95        0.157895          0.126316   \n",
       "347                  288        0.322917          0.291667   \n",
       "83                   593        0.372681          0.342327   \n",
       "53                   102        0.235294          0.205882   \n",
       "112                  206        0.310680          0.281553   \n",
       "346                  209        0.320574          0.291866   \n",
       "297                  113        0.265487          0.238938   \n",
       "11                   199        0.316583          0.291457   \n",
       "187                  325        0.304615          0.280000   \n",
       "54                   214        0.228972          0.205607   \n",
       "4                     96        0.364583          0.343750   \n",
       "227                   98        0.265306          0.244898   \n",
       "146                  197        0.279188          0.258883   \n",
       "267                  299        0.207358          0.187291   \n",
       "149                  804        0.430348          0.410448   \n",
       "329                  102        0.137255          0.117647   \n",
       "302                  312        0.262821          0.243590   \n",
       "65                   477        0.243187          0.224319   \n",
       "43                   432        0.201389          0.182870   \n",
       "\n",
       "     aggression_over_expected  \n",
       "363                  0.050847  \n",
       "166                  0.048000  \n",
       "139                  0.042105  \n",
       "170                  0.038835  \n",
       "201                  0.036471  \n",
       "75                   0.033223  \n",
       "245                  0.031579  \n",
       "347                  0.031250  \n",
       "83                   0.030354  \n",
       "53                   0.029412  \n",
       "112                  0.029126  \n",
       "346                  0.028708  \n",
       "297                  0.026549  \n",
       "11                   0.025126  \n",
       "187                  0.024615  \n",
       "54                   0.023364  \n",
       "4                    0.020833  \n",
       "227                  0.020408  \n",
       "146                  0.020305  \n",
       "267                  0.020067  \n",
       "149                  0.019900  \n",
       "329                  0.019608  \n",
       "302                  0.019231  \n",
       "65                   0.018868  \n",
       "43                   0.018519  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full rankings table\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FULL AGGRESSION RANKINGS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "coach_aggression[[\n",
    "    'aggression_rank', 'coach_name', 'primary_team', \n",
    "    'total_opportunities', 'actual_go_rate', 'expected_go_rate', \n",
    "    'aggression_over_expected'\n",
    "]].head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING OUTPUTS\n",
      "============================================================\n",
      "✓ Saved: coach_aggression_rankings.csv\n",
      "✓ Saved: play_level_predictions.csv\n",
      "✓ Saved: final_fourth_down_model.joblib\n",
      "✓ Saved: feature_scaler.joblib\n",
      "✓ Saved: final_model_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAVING OUTPUTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save coach aggression rankings\n",
    "coach_aggression.to_csv('coach_aggression_rankings.csv', index=False)\n",
    "print(\"✓ Saved: coach_aggression_rankings.csv\")\n",
    "\n",
    "# Save play-level predictions\n",
    "play_results.to_csv('play_level_predictions.csv', index=False)\n",
    "print(\"✓ Saved: play_level_predictions.csv\")\n",
    "\n",
    "# Save the final model\n",
    "joblib.dump(tuned_model, 'final_fourth_down_model.joblib')\n",
    "print(\"✓ Saved: final_fourth_down_model.joblib\")\n",
    "\n",
    "# Save scaler if used\n",
    "if scaler is not None:\n",
    "    joblib.dump(scaler, 'feature_scaler.joblib')\n",
    "    print(\"✓ Saved: feature_scaler.joblib\")\n",
    "\n",
    "# Save final metrics\n",
    "metrics_df = pd.DataFrame([{\n",
    "    'model': best_model_name,\n",
    "    'best_params': str(best_params),\n",
    "    **final_metrics\n",
    "}])\n",
    "metrics_df.to_csv('final_model_metrics.csv', index=False)\n",
    "print(\"✓ Saved: final_model_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PIPELINE COMPLETE\n",
      "============================================================\n",
      "\n",
      "Dataset Summary:\n",
      "  Total plays analyzed: 200,056\n",
      "  Coaches ranked: 367\n",
      "  Years covered: 2015 - 2025\n",
      "\n",
      "Model Summary:\n",
      "  Best model: Random Forest\n",
      "  F1-Score: 0.7470\n",
      "  Accuracy: 0.8967\n",
      "\n",
      "Output Files:\n",
      "  • coach_aggression_rankings.csv\n",
      "  • play_level_predictions.csv\n",
      "  • model_comparison_results.csv\n",
      "  • final_fourth_down_model.joblib\n",
      "  • final_model_metrics.csv\n",
      "\n",
      "Most Aggressive: Willie Simmons (AOE: +0.051)\n",
      "Most Conservative: Scott Shafer (AOE: -0.028)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PIPELINE COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"  Total plays analyzed: {len(X):,}\")\n",
    "print(f\"  Coaches ranked: {len(coach_aggression)}\")\n",
    "print(f\"  Years covered: {metadata['year'].min()} - {metadata['year'].max()}\")\n",
    "\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(f\"  Best model: {best_model_name}\")\n",
    "print(f\"  F1-Score: {final_metrics['f1']:.4f}\")\n",
    "print(f\"  Accuracy: {final_metrics['accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nOutput Files:\")\n",
    "print(f\"  • coach_aggression_rankings.csv\")\n",
    "print(f\"  • play_level_predictions.csv\")\n",
    "print(f\"  • model_comparison_results.csv\")\n",
    "print(f\"  • final_fourth_down_model.joblib\")\n",
    "print(f\"  • final_model_metrics.csv\")\n",
    "\n",
    "print(f\"\\nMost Aggressive: {coach_aggression.iloc[0]['coach_name']} (AOE: {coach_aggression.iloc[0]['aggression_over_expected']:+.3f})\")\n",
    "print(f\"Most Conservative: {coach_aggression.iloc[-1]['coach_name']} (AOE: {coach_aggression.iloc[-1]['aggression_over_expected']:+.3f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
